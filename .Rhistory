read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_nodes(playerIDTable) %>%
html_attr(name="href") %>% unlist %>% as.character -> playerIDhtml
# clean dataframe and add team and season info
colnames(df) <- paste0(colnames(df), df[1,])
df
df <- df[-1, ]
df$season <- c(season)
df <- df %>% filter(!School %in% c("School", NA, ""))
playerIDhtml <- grep("players",x = playerIDhtml,value = TRUE)
# remove url data
playerIDhtml=gsub("/cfb/players/", "", playerIDhtml,fixed = TRUE)
playerID=gsub(".html", "", playerIDhtml,fixed = TRUE)
df$playerID <- c(playerID)
rushingDataGames <- data.frame()
# for loop by season
for (urls in urls[1:2]) {
# batting stats
urls %>%
read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_node(rushingTable) %>%
html_table(header = TRUE) -> df
# player info
urls %>%
read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_nodes(playerIDTable) %>%
html_attr(name="href") %>% unlist %>% as.character -> playerIDhtml
# clean dataframe and add team and season info
colnames(df) <- paste0(colnames(df), df[1,])
df <- df[-1, ]
df$season <- c(season)
df <- df %>% filter(!School %in% c("School", NA, ""))
playerIDhtml <- grep("players",x = playerIDhtml,value = TRUE)
# remove url data
playerIDhtml=gsub("/cfb/players/", "", playerIDhtml,fixed = TRUE)
playerID=gsub(".html", "", playerIDhtml,fixed = TRUE)
df$playerID <- c(playerID)
# bind to
rushingDataGames <- rbind(rushingDataGames,df)
}
traceback()
rushingDataGames
rm(list=ls())
url <- "https://www.sports-reference.com/cfb/schools/wisconsin/"
rushingTable <- '#rushing_and_receiving'
playerIDTable <- paste0(rushingTable,' a')
rushingData <- data.frame()
urlFirst <- "https://www.sports-reference.com/cfb/schools/wisconsin/"
urlSecond <- "https://www.sports-reference.com"
offenseYear <- "#offense"
gameDate <- paste0(offenseYear,' a')
urls <- c()
for (season in 2000:2018) {
html <- paste0(urlFirst,season,"/gamelog/")
# player info
html %>%
read_html() %>%
html_nodes(gameDate) %>%
html_attr(name="href") %>% unlist %>% as.character -> playerIDhtml
playerIDhtml <- grep("boxscores",x = playerIDhtml,value = TRUE)
html2 <- paste0(urlSecond,playerIDhtml)
# bind to
urls <- c(urls,html2)
}
urls
# for loop by season
for (urls in urls[1:2]) {
# batting stats
urls %>%
read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_node(rushingTable) %>%
html_table(header = TRUE) -> df
# player info
urls %>%
read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_nodes(playerIDTable) %>%
html_attr(name="href") %>% unlist %>% as.character -> playerIDhtml
# clean dataframe and add team and season info
colnames(df) <- paste0(colnames(df), df[1,])
df <- df[-1, ]
df$season <- c(season)
df <- df %>% filter(!School %in% c("School", NA, ""))
playerIDhtml <- grep("players",x = playerIDhtml,value = TRUE)
# remove url data
playerIDhtml=gsub("/cfb/players/", "", playerIDhtml,fixed = TRUE)
playerID=gsub(".html", "", playerIDhtml,fixed = TRUE)
df$playerID <- c(playerID)
# bind to
rushingDataGames <- rbind(rushingDataGames,df)
}
rushingData
rushingDataGames
rushingTable
rushingDataGames <- data.frame()
# for loop by season
for (urls in urls[1:2]) {
# batting stats
urls %>%
read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_node(rushingTable) %>%
html_table(header = TRUE) -> df
# player info
urls %>%
read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_nodes(playerIDTable) %>%
html_attr(name="href") %>% unlist %>% as.character -> playerIDhtml
# clean dataframe and add team and season info
colnames(df) <- paste0(colnames(df), df[1,])
df <- df[-1, ]
df$season <- c(season)
df <- df %>% filter(!School %in% c("School", NA, ""))
playerIDhtml <- grep("players",x = playerIDhtml,value = TRUE)
# remove url data
playerIDhtml=gsub("/cfb/players/", "", playerIDhtml,fixed = TRUE)
playerID=gsub(".html", "", playerIDhtml,fixed = TRUE)
df$playerID <- c(playerID)
# bind to
rushingDataGames <- rbind(rushingDataGames,df)
}
rushingDataGames <- data.frame()
# for loop by season
for (urls in urls[1:2]) {
# batting stats
urls %>%
read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_node(rushingTable) %>%
html_table(header = TRUE) -> df
# player info
urls %>%
read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_nodes(playerIDTable) %>%
html_attr(name="href") %>% unlist %>% as.character -> playerIDhtml
# clean dataframe and add team and season info
colnames(df) <- paste0(colnames(df), df[1,])
df <- df[-1, ]
df$season <- c(season)
df <- df %>% filter(!School %in% c("School", ""))
playerIDhtml <- grep("players",x = playerIDhtml,value = TRUE)
# remove url data
playerIDhtml=gsub("/cfb/players/", "", playerIDhtml,fixed = TRUE)
playerID=gsub(".html", "", playerIDhtml,fixed = TRUE)
df$playerID <- c(playerID)
# bind to
rushingDataGames <- rbind(rushingDataGames,df)
}
rushingDataGames <- data.frame()
# for loop by season
for (urls in urls[1:2]) {
# batting stats
urls %>%
read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_node(rushingTable) %>%
html_table(header = TRUE) -> df
# player info
urls %>%
read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_nodes(playerIDTable) %>%
html_attr(name="href") %>% unlist %>% as.character -> playerIDhtml
# clean dataframe and add team and season info
colnames(df) <- paste0(colnames(df), df[1,])
df <- df[-1, ]
df$season <- c(season)
df <- df %>% filter(!School %in% c("School", ""))
playerIDhtml <- grep("players",x = playerIDhtml,value = TRUE)
# remove url data
playerIDhtml=gsub("/cfb/players/", "", playerIDhtml,fixed = TRUE)
playerID=gsub(".html", "", playerIDhtml,fixed = TRUE)
df$playerID <- c(playerID)
print(df)
# bind to
rushingDataGames <- rbind(rushingDataGames,df)
}
getwd()
urls
urls <- c()
for (season in 2000:2018) {
html <- paste0(urlFirst,season,"/gamelog/")
# player info
html %>%
read_html() %>%
html_nodes(gameDate) %>%
html_attr(name="href") %>% unlist %>% as.character -> playerIDhtml
playerIDhtml <- grep("boxscores",x = playerIDhtml,value = TRUE)
html2 <- paste0(urlSecond,playerIDhtml)
# bind to
urls <- c(urls,html2)
}
urls
# for loop by season
for (links in urls[1:2]) {
# batting stats
links %>%
read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_node(rushingTable) %>%
html_table(header = TRUE) -> df
# player info
links %>%
read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_nodes(playerIDTable) %>%
html_attr(name="href") %>% unlist %>% as.character -> playerIDhtml
# clean dataframe and add team and season info
colnames(df) <- paste0(colnames(df), df[1,])
df <- df[-1, ]
df$season <- c(season)
df <- df %>% filter(!School %in% c("School", NA, ""))
playerIDhtml <- grep("players",x = playerIDhtml,value = TRUE)
# remove url data
playerIDhtml=gsub("/cfb/players/", "", playerIDhtml,fixed = TRUE)
playerID=gsub(".html", "", playerIDhtml,fixed = TRUE)
df$playerID <- c(playerID)
# bind to
rushingDataGames <- rbind(rushingDataGames,df)
}
View(rushingDataGames)
urls
# for loop by season
for (links in urls) {
# batting stats
links %>%
read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_node(rushingTable) %>%
html_table(header = TRUE) -> df
# player info
links %>%
read_html %>%
html_nodes(xpath = '//comment()') %>%
html_text() %>%
paste(collapse='') %>%
read_html() %>%
html_nodes(playerIDTable) %>%
html_attr(name="href") %>% unlist %>% as.character -> playerIDhtml
# clean dataframe and add team and season info
colnames(df) <- paste0(colnames(df), df[1,])
df <- df[-1, ]
df$season <- c(season)
df <- df %>% filter(!School %in% c("School", NA, ""))
playerIDhtml <- grep("players",x = playerIDhtml,value = TRUE)
# remove url data
playerIDhtml=gsub("/cfb/players/", "", playerIDhtml,fixed = TRUE)
playerID=gsub(".html", "", playerIDhtml,fixed = TRUE)
df$playerID <- c(playerID)
# bind to
rushingDataGames <- rbind(rushingDataGames,df)
}
View(rushingDataGames)
links
table(rushingDataGames$season)
4/7
library(ggplot2)
library(patchwork)
b <- ggplot() +
annotate('rect', xmin=0, ymin=0, xmax=1, ymax=1, fill=NA) +
theme_void()
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Define a plot with just a rectangle
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
p <- ggplot() +
annotate('rect', xmin=0, ymin=0, xmax=1, ymax=1) +
theme_void()
p
f <- function(p) {
wrap_plots(
wrap_plots(b, p, b, widths = c(0.5, 1, 0.5)),
wrap_plots(p, p),
ncol = 1L
)
}
f(p)
f(p)
dev.off()
print(f(p))
grid.draw(f(p))
library(grid)
grid.draw(f(p))
dev.off()
grid.draw(f(p))
dev.off()
f(p)
library(ggplot2)
library(gganimate)
p <- ggplot(airquality, aes(Day, Temp)) +
geom_line(size = 2, colour = 'steelblue') +
transition_states(Month, 4, 1) +
shadow_mark(size = 1, colour = 'grey')
animate(p, renderer = ffmpeg_renderer())
library(gapminder)
library(ggplot2)
library(tweenr)
library(dplyr)
library(gganimate)
datalist <- split(gapminder, gapminder$year)
dat <- tween_states(datalist, 2, 1, 'linear', 100)
datalist <- split(dat, dat$year)
countries <- gapminder %>% filter(country %in% c("Afghanistan", "Albania", "Algeria", "Argentina", "Australia"))
datalist <- split(countries, countries$year,drop = TRUE)
dat <- tween_states(datalist, 2, 1, 'linear', 100)
datalist <- split(dat, dat$year)
dat
makeplot <- function(){
for (i in 1:max(dat$.frame)) {
p <- ggplot(data = subset(dat, .frame <= i), aes(year, gdpPercap, color = country, group = country))  + geom_line( )  +  scale_x_continuous(limits = range(gapminder$year))
print(p)
}
}
# High Definition images:
gif_file <- file.path(paste0(getwd(), '/gifskiGapminderLine.gif'))
save_gif(makeplot(), gif_file, 1280, 720, res = 144, delay = .1)
utils::browseURL(gif_file)
library(gifski)
makeplot <- function(){
for (i in 1:max(dat$.frame)) {
p <- ggplot(data = subset(dat, .frame <= i), aes(year, gdpPercap, color = country, group = country))  + geom_line( )  +  scale_x_continuous(limits = range(gapminder$year))
print(p)
}
}
# High Definition images:
gif_file <- file.path(paste0(getwd(), '/gifskiGapminderLine.gif'))
save_gif(makeplot(), gif_file, 1280, 720, res = 144, delay = .1)
utils::browseURL(gif_file)
datalist <- split(countries, countries$year,drop = TRUE)
dat <- tween_states(datalist, 1, 1, 'linear', 100)
# gifski
makeplot <- function(){
for (i in 1:max(dat$.frame)) {
p <- ggplot(data = subset(dat, .frame <= i), aes(year, gdpPercap, color = country, group = country))  + geom_line( )  +  scale_x_continuous(limits = range(gapminder$year)) +  scale_y_continuous(limits = range(gapminder$gdpPercap))
print(p)
}
}
# High Definition images:
gif_file <- file.path(paste0(getwd(), '/gifskiGapminderLine.gif'))
save_gif(makeplot(), gif_file, 1280, 720, res = 144, delay = .1)
utils::browseURL(gif_file)
View(dat)
tween_states()
?tween_states
datalist <- split(countries, countries$year,drop = TRUE)
dat <- tween_states(datalist, tweenlength = 1, statelength = 0, 'linear', 100)
# gifski
makeplot <- function(){
for (i in 1:max(dat$.frame)) {
p <- ggplot(data = subset(dat, .frame <= i), aes(year, gdpPercap, color = country, group = country))  + geom_line( )  +  scale_x_continuous(limits = range(gapminder$year)) +  scale_y_continuous(limits = c(0,40000))
print(p)
}
}
# High Definition images:
gif_file <- file.path(paste0(getwd(), '/gifskiGapminderLine.gif'))
save_gif(makeplot(), gif_file, 1280, 720, res = 144, delay = .1)
utils::browseURL(gif_file)
?image_animate
library(magick)
?image_animate
img <- image_graph(1280, 720, res = 144)
dev.off()
img <- image_graph(1280, 720, res = 144)
dev.off()
dev.off()
?image_graph
makeplot <- function(){
lapply(datalist, function(data){
p <- ggplot(data, aes(gdpPercap, lifeExp, size = pop, color = continent)) +
scale_size("population", limits = range(gapminder$pop)) + geom_point() + ylim(20, 90) +
scale_x_log10(limits = range(gapminder$gdpPercap)) + ggtitle(data$year) + theme_classic()
print(p)
})
}
saveGIF(makeplot(),movie.name="/home/michael/Documents/NCESgifs/lineCompletion/lineCompletionLarge.gif",interval = .02, ani.width = 1200, ani.height = 800)
library(animation)
makeplot <- function(){
lapply(datalist, function(data){
p <- ggplot(data, aes(gdpPercap, lifeExp, size = pop, color = continent)) +
scale_size("population", limits = range(gapminder$pop)) + geom_point() + ylim(20, 90) +
scale_x_log10(limits = range(gapminder$gdpPercap)) + ggtitle(data$year) + theme_classic()
print(p)
})
}
saveGIF(makeplot(),movie.name="/home/michael/Documents/NCESgifs/lineCompletion/lineCompletionLarge.gif",interval = .02, ani.width = 1200, ani.height = 800)
datalist <- split(gapminder, gapminder$year)
dat <- tween_states(datalist, 2, 1, 'linear', 100)
datalist <- split(dat, dat$year)
makeplot <- function(){
lapply(datalist, function(data){
p <- ggplot(data, aes(gdpPercap, lifeExp, size = pop, color = continent)) +
scale_size("population", limits = range(gapminder$pop)) + geom_point() + ylim(20, 90) +
scale_x_log10(limits = range(gapminder$gdpPercap)) + ggtitle(data$year) + theme_classic()
print(p)
})
}
saveGIF(makeplot(),movie.name=paste0(getwd(), '/animationapminder.gif'),interval = .02, ani.width = 1200, ani.height = 800)
?animate
devtools::install_github('thomasp85/gganimate')
library(gapminder)
library(dplyr)
library(ggplot2)
countries <- gapminder %>% filter(country %in% c("Afghanistan", "Albania", "Algeria", "Argentina", "Australia"))
library(tweenr)
datalist <- split(countries, countries$year,drop = TRUE)
datTweened <- tween_states(datalist, tweenlength = 1,
statelength = 0, 'linear', 100)
datalistTweened <- split(datTweened, datTweened$year)
lapply(datalistTweened, unique)
lapply(datalistTweened, unique(datalistTweened$year))
lapply(datalistTweened, unique(year))
lapply(datalistTweened, unique())
lapply(datalistTweened, unique)
lapply(datalistTweened, unique)
sapply(datalistTweened, unique)
unique(datalistTweened)
unique(datalistTweened$`1952`)
table(datalistTweened)
table(datalistTweened[[1]])
glimpse(datalistTweened)
glimpse(datTweened)
datTweened
setwd('/home/michael/Documents/mikeleeco.github.com/')
library(blogdown)
# file.create('.nojekyll')
# blogdown::build_site()
# blogdown::hugo_build()
# serve_site should build the site without errors and display it in the viewer. It's now ready to be pushed to master on github
blogdown::serve_site()
# library(servr)
# library(knitr)
# setwd('/home/michael/Documents/mikeleeco.github.com/')
# jekyll()
# # jekyll(command = '/home/michael/.rbenv/shims/jekyll build')
# jekyll(input = "_source", command = '/home/michael/.rbenv/versions/2.3.1/bin/bundle exec jekyll serve')
# servr::jekyll(command = '/.rvm/gems/ruby-2.3.1/wrappers/jekyll build')
#
# export PATH=$PATH:/home/michael/.rbenv/versions/2.3.1/bin
# .libPaths("/home/michael/R/x86_64-pc-linux-gnu-library/3.4.1")
# .libPaths(new = "/home/michael/R/x86_64-pc-linux-gnu-library/3.4")
setwd('/home/michael/Documents/mikeleeco.github.com/')
library(blogdown)
# file.create('.nojekyll')
# blogdown::build_site()
# blogdown::hugo_build()
# serve_site should build the site without errors and display it in the viewer. It's now ready to be pushed to master on github
blogdown::serve_site()
# library(servr)
# library(knitr)
# setwd('/home/michael/Documents/mikeleeco.github.com/')
# jekyll()
# # jekyll(command = '/home/michael/.rbenv/shims/jekyll build')
# jekyll(input = "_source", command = '/home/michael/.rbenv/versions/2.3.1/bin/bundle exec jekyll serve')
# servr::jekyll(command = '/.rvm/gems/ruby-2.3.1/wrappers/jekyll build')
#
# export PATH=$PATH:/home/michael/.rbenv/versions/2.3.1/bin
# .libPaths("/home/michael/R/x86_64-pc-linux-gnu-library/3.4.1")
# .libPaths(new = "/home/michael/R/x86_64-pc-linux-gnu-library/3.4")
setwd('/home/michael/Documents/mikeleeco.github.com/')
library(blogdown)
# file.create('.nojekyll')
# blogdown::build_site()
# blogdown::hugo_build()
# serve_site should build the site without errors and display it in the viewer. It's now ready to be pushed to master on github
blogdown::serve_site()
