yDates[1] <- 1
saveGIF({
for (i in yDates) {
gg2 <- gg + geom_point(data = subset(dischargeByDay, day <=i), aes(x = day, y = avgDischarge), alpha = .1)
g <- ggplotGrob(gg2)
g$layout$l[g$layout$name == "title"] <- 3
g$layout$l[g$layout$name == "caption"] <- 3
g$layout$l[g$layout$name == "subtitle"] <- 3
grid::grid.draw(g);
grid.newpage()
}
grid::grid.draw(g);
replicate(10,gifReplicate(g))
for (i in seq(from =1, to = 366, by = 7)) {
gg3 <- gg2 + geom_segment(x = 1, xend = i, y = 150,yend = 150, color= "red", linetype = 2)
g <- ggplotGrob(gg3)
g$layout$l[g$layout$name == "title"] <- 3
g$layout$l[g$layout$name == "caption"] <- 3
g$layout$l[g$layout$name == "subtitle"] <- 3
grid::grid.draw(g);
grid.newpage()
}
for (i in yDates) {
gg4 <- gg3 + stat_smooth(data = subset(dischargeByDayYear, day <=i), aes(x = day), se = F, method = "lm", formula = y ~ poly(x, 20))
g <- ggplotGrob(gg4)
g$layout$l[g$layout$name == "title"] <- 3
g$layout$l[g$layout$name == "caption"] <- 3
g$layout$l[g$layout$name == "subtitle"] <- 3
grid::grid.draw(g);
grid.newpage()
}
grid::grid.draw(g);
replicate(100,gifReplicate(g))
# grid.draw(gg4)
# geom_hline(yintercept = 150, color= "red", linetype = 2) +
#   geom_line(aes(x=day, y=avgDischarge), size=1.3) +
},movie.name=paste0(getwd(),"/narrowsLarge2.gif"),interval = .02, ani.width = 1200, ani.height = 800)
gif_compress <- function(ingif, outgif, show=TRUE, extra.opts=""){
command <-  sprintf("gifsicle -O3 %s < %s > %s", extra.opts, ingif, outgif)
system.fun <- if (.Platform$OS.type == "windows") shell else system
if(show) message("Executing: ", strwrap(command, exdent = 2, prefix = "\n"))
system.fun(ifelse(.Platform$OS.type == "windows", sprintf("\"%s\"", shQuote(command)), command))
}
gif_compress(paste0(getwd(),"/narrowsLarge2.gif"),
paste0(getwd(),"/narrowsLargeTall2.gif"))
getwd()
gg3 + stat_smooth(data = subset(dischargeByDayYear, day <=i), aes(x = day), se = F, method = "lm", formula = y ~ poly(x, 20))
subset(dischargeByDayYear, day <=i)
gg3 + stat_smooth(data = subset(dischargeByDayYear, day <=i), aes(x = day), se = F, method = "lm", formula = y ~ poly(x, 5))
gg3 + stat_smooth(data = subset(dischargeByDayYear, day <=i), aes(x = day), se = F, method = "lm", formula = y ~ poly(x, 2))
gg3 + stat_smooth(data = subset(dischargeByDayYear, day <=i), aes(x = day), se = F, method = "lm", formula = y ~ poly(x, 11))
gg3 + stat_smooth(data = subset(dischargeByDayYear, day <=i), aes(x = day), se = F, method = "lm", formula = y ~ poly(x, 10))
gg3 + stat_smooth(data = subset(dischargeByDayYear, day <=i), aes(x = day), se = F, method = "lm", formula = y ~ poly(x, 15))
gg3 + stat_smooth(data = subset(dischargeByDayYear, day <=i), aes(x = day), se = F, method = "lm", formula = y ~ poly(x, 30))
gg3 + stat_smooth(data = subset(dischargeByDayYear, day <=i), aes(x = day), se = F, method = "lm", formula = y ~ poly(x, 24))
gg3 + stat_smooth(data = subset(dischargeByDayYear, day <=i), aes(x = day), se = F, method = "lm", formula = y ~ poly(x, 25))
gg3 + stat_smooth(data = subset(dischargeByDayYear, day <=i), aes(x = day), se = F, method = "lm", formula = y ~ poly(x, 26))
unique(x$time)
hms(x$time)
hm(x$time)
x$timetry <- hm(x$time)
table(x$timetry)
table(x$timetry,useNA = "ifany")
?HM
?hm
x[718531]
x[718531,]
x[718531,6]
x[718531,6] + 12
v <- subset(x, grepl("PM",x$time))
View(v)
table(as.character(v$timetry))
gg <- ggplot(dischargeByDay, aes(x = day, y = avgDischarge, group = 1)) +
geom_point(aes(x = day, y = avgDischarge), alpha = .1) +
stat_smooth(aes(x = day), se = F, method = "lm", formula = y ~ poly(x, 20)) +
geom_segment(x = 1, xend = 366, y = 150,yend = 150, color= "red", linetype = 2) +
scale_y_continuous(limits = c(0, 350), expand = c(0,0)) +
scale_x_date(date_breaks = "1 month", date_labels =  "%b", expand = c(0,0),limits = c(min(dischargeByDay$day),max(dischargeByDay$day))) +
labs(title = "Mean Flow of the VIRGIN RIVER NARROWS by day (1993 - 2018)",
subtitle = "If the river is flowing at over 150 Cubic Feet per Second (CFS) the narrows is closed",
caption = "Data Accessed 3/16/2018, retrieved via https://nwis.waterdata.usgs.gov/usa/nwis/uv/") +
theme_bw() + theme(plot.caption = element_text(hjust=0))
gg
x$timetry <- as.character(x$timetry)
x <- x %>% separate(timetry, c("hour", "minute", "second"), " ", extra = "merge")
?separate
v2 <- v %>% separate(timetry, c("hour", "minute", "second"), " ", extra = "drop")
View(v2)
# ---------------------------------- WARNING ----------------------------------------
# Some of the data that you have obtained from this U.S. Geological Survey database
# may not have received Director's approval. Any such data values are qualified
# as provisional and are subject to revision. Provisional data are released on the
# condition that neither the USGS nor the United States Government may be held liable
# for any damages resulting from its use.
#
# Additional info: https://help.waterdata.usgs.gov/policies/provisional-data-statement
#
# File-format description:  https://help.waterdata.usgs.gov/faq/about-tab-delimited-output
# Automated-retrieval info: https://help.waterdata.usgs.gov/faq/automated-retrievals
#
# Contact:   gs-w_support_nwisweb@usgs.gov
# retrieved: 2018-03-15 12:29:46 EDT       (nadww01)
#
# Data for the following 1 site(s) are contained in this file
#    USGS 09405500 NORTH FORK VIRGIN RIVER NEAR SPRINGDALE, UT
# -----------------------------------------------------------------------------------
#
# Data provided for site 09405500
#            TS   parameter     Description
#        144196       00060     Discharge, cubic feet per second
#
# Data-value qualification codes included in this output:
#     A  Approved for publication -- Processing and review completed.
#     P  Provisional data subject to revision.
#     0  UNDEF
#    91  Daily mean calculated from data on this day matches published daily mean within 1 percent
#    92  Daily mean calculated from data on this day matches published daily mean within 5 percent
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(animation)
library(grid)
x <- read.csv("website/narrows/narrows.csv", row.names = NULL, stringsAsFactors = FALSE)
x <- x[1:530086,]
x2 <- read.csv("website/narrows/narrows2.csv", row.names = NULL, stringsAsFactors = FALSE)
x <- rbind(x,x2)
rm(x2)
x <- x %>% separate(datetime, c("date", "time"), " ", extra = "merge")
x$date <- mdy(x$date)
x$timetry <- hm(x$time)
x2 <- x %>% separate(timetry, c("hour", "minute", "second"), " ", extra = "drop")
View(x2)
x2 <- x %>% separate(timetry, c("hour", "minute", "second"), " ", extra = "merge", fill = "right")
View(x2)
x2 <- x %>% separate(timetry, c("hour", "minute", "second"), " ", extra = "merge", fill = "left")
# ---------------------------------- WARNING ----------------------------------------
# Some of the data that you have obtained from this U.S. Geological Survey database
# may not have received Director's approval. Any such data values are qualified
# as provisional and are subject to revision. Provisional data are released on the
# condition that neither the USGS nor the United States Government may be held liable
# for any damages resulting from its use.
#
# Additional info: https://help.waterdata.usgs.gov/policies/provisional-data-statement
#
# File-format description:  https://help.waterdata.usgs.gov/faq/about-tab-delimited-output
# Automated-retrieval info: https://help.waterdata.usgs.gov/faq/automated-retrievals
#
# Contact:   gs-w_support_nwisweb@usgs.gov
# retrieved: 2018-03-15 12:29:46 EDT       (nadww01)
#
# Data for the following 1 site(s) are contained in this file
#    USGS 09405500 NORTH FORK VIRGIN RIVER NEAR SPRINGDALE, UT
# -----------------------------------------------------------------------------------
#
# Data provided for site 09405500
#            TS   parameter     Description
#        144196       00060     Discharge, cubic feet per second
#
# Data-value qualification codes included in this output:
#     A  Approved for publication -- Processing and review completed.
#     P  Provisional data subject to revision.
#     0  UNDEF
#    91  Daily mean calculated from data on this day matches published daily mean within 1 percent
#    92  Daily mean calculated from data on this day matches published daily mean within 5 percent
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(animation)
library(grid)
x <- read.csv("website/narrows/narrows.csv", row.names = NULL, stringsAsFactors = FALSE)
x <- x[1:530086,]
x2 <- read.csv("website/narrows/narrows2.csv", row.names = NULL, stringsAsFactors = FALSE)
x <- rbind(x,x2)
rm(x2)
x <- x %>% separate(datetime, c("date", "time"), " ", extra = "merge")
x$date <- mdy(x$date)
x$timeparse <- hm(x$time)
x2 <- x %>% separate(timeparse, c("hour", "minute", "second"), " ", extra = "merge", fill = "left")
x <- x2
x$hour <- gsub("H", "", x$hour)
x$minute <- gsub("M", "", x$minute)
x$second <- gsub("S", "", x$second)
table(x$hour)
table(x$hour,useNA = "ifany")
table(x$minute,useNA = "ifany")
table(x$second,useNA = "ifany")
x[,c("hour","minute","second")] <- sapply(x[,c("hour","minute","second")], as.numeric)
sapply(x,class)
x$hour <- ifelse(grepl("PM", x$time, x$hour + 12),x$hour)
x$hour <- ifelse(grepl("PM", x$time), x$hour + 12,x$hour)
x$timeUpdate <- paste(x$hour,x$minute,x$second)
x$timeUpdate <- paste(x$hour,x$minute,x$second,sep = ":")
x$hour <- ifelse(is.na(x$hour),0 ,x$hour)
x$minute <- ifelse(is.na(x$minute),0 ,x$minute)
x <- read.csv("website/narrows/narrows.csv", row.names = NULL, stringsAsFactors = FALSE)
x <- x[1:530086,]
x2 <- read.csv("website/narrows/narrows2.csv", row.names = NULL, stringsAsFactors = FALSE)
x <- rbind(x,x2)
rm(x2)
x <- x %>% separate(datetime, c("date", "time"), " ", extra = "merge")
x$date <- mdy(x$date)
x$timeparse <- hm(x$time)
x <- x %>% separate(timeparse, c("hour", "minute", "second"), " ", extra = "merge", fill = "left")
x$hour <- gsub("H", "", x$hour)
x$minute <- gsub("M", "", x$minute)
x$second <- gsub("S", "", x$second)
x[,c("hour","minute","second")] <- sapply(x[,c("hour","minute","second")], as.numeric)
x$hour <- ifelse(is.na(x$hour),0 ,x$hour)
x$minute <- ifelse(is.na(x$minute),0 ,x$minute)
x$hour <- ifelse(grepl("PM", x$time, x$hour + 12),x$hour)
x$hour <- ifelse(grepl("PM", x$time), x$hour + 12,x$hour)
nchar(12)
x$hour <- ifelse(nchar(x$hour) > 2, paste0(0,x$hour),x$hour)
x$minute <- ifelse(nchar(x$minute) > 2, paste0(0,x$minute),x$minute)
x$second <- ifelse(nchar(x$second) > 2, paste0(0,x$second),x$second)
x$hour <- ifelse(nchar(x$hour) > 2, paste0("0",as.character(x$hour)),as.character(x$hour))
x$minute <- ifelse(nchar(x$minute) > 2, paste0("0",as.character(x$minute)),as.character(x$minute))
x$second <- ifelse(nchar(x$second) > 2, paste0("0",as.character(x$second)),as.character(x$second))
x$second
sapply(x,class)
table(x$second)
table(x$hour)
paste0("0",as.character(x$hour[1]))
x$hour <- ifelse(nchar(x$hour) < 2, paste0("0",as.character(x$hour)),as.character(x$hour))
x$minute <- ifelse(nchar(x$minute) < 2, paste0("0",as.character(x$minute)),as.character(x$minute))
x$second <- ifelse(nchar(x$second) < 2, paste0("0",as.character(x$second)),as.character(x$second))
table(x$hour)
x$timeUpdate <- paste(x$hour,x$minute,x$second, sep = ":")
table(x$timeUpdate)
x$hour <- ifelse(grepl("24:", x$hour), "00:",x$hour)
x$timeUpdate <- paste(x$hour,x$minute,x$second, sep = ":")
table(x$timeUpdate)
x$hour <- ifelse(grepl("24:", x$hour,perl = TRUE), "00:",x$hour)
table(x$timeUpdate)
?grepl
x$hour <- ifelse(grepl("24", x$hour), "00",x$hour)
table(x$hour)
x$timeUpdate <- paste(x$hour,x$minute,x$second, sep = ":")
table(x$timeUpdate)
x %>% filter(date %in% month(4))
View(dischargeByDay)
dischargeByDay <- x %>% mutate(day = yday(date)) %>% group_by(day) %>% summarise(avgDischarge = mean(discharge, na.rm = TRUE))
View(dischargeByDay)
table(month(x$date))
dischargeByAprilHour <- x %>% filter(month(date) == 4)%>% group_by(day,hour) %>% summarise(avgDischarge = mean(discharge, na.rm = TRUE))
dischargeByAprilHour <- x %>% filter(month(date) == 4) %>% mutate(day = yday(date)) %>% group_by(day,hour) %>% summarise(avgDischarge = mean(discharge, na.rm = TRUE))
View(dischargeByAprilHour)
plot(dischargeByAprilHour$day, dischargeByAprilHour$avgDischarge)
dischargeByAprilHour <- x %>% filter(month(date) == 4) %>% mutate(day = yday(date)) %>% group_by(hour) %>% summarise(avgDischarge = mean(discharge, na.rm = TRUE))
plot(dischargeByAprilHour$day, dischargeByAprilHour$avgDischarge)
plot(dischargeByAprilHour$hour, dischargeByAprilHour$avgDischarge)
install.packages('blogdown')
devtools::install_github('rstudio/blogdown')
library(blogdown)
library(animation)
saveGIF({
for (i in 1:10) plot(runif(10), ylim = 0:1)
},loop=TRUE,interval=0.2)
library(animation)
saveGIF({
for (i in 1:10) plot(runif(10), ylim = 0:1)
},loop=FALSE,interval=0.2)
?saveGIF
ani.options()
ani.options(loop = FALSE)
ani.options()
library(animation)
saveGIF({
for (i in 1:10) plot(runif(10), ylim = 0:1)
},interval=0.2)
dev.off()
ani.options(loop = 1)
library(animation)
saveGIF({
for (i in 1:10) plot(runif(10), ylim = 0:1)
},interval=0.2)
install.packages(c("arm", "bdsmatrix", "bindr", "bindrcpp", "bit", "broom", "car", "caret", "checkmate", "chron", "classInt", "commonmark", "covr", "crayon", "crul", "curl", "data.table", "DBI", "desc", "devtools", "digest", "dplyr", "DT", "egg", "forcats", "foreach", "Formula", "geofacet", "ggforce", "ggjoy", "git2r", "gridExtra", "gtools", "haven", "hexbin", "highr", "Hmisc", "hms", "htmlTable", "htmlwidgets", "httpuv", "hunspell", "igraph", "irlba", "iterators", "later", "lavaan", "lintr", "lme4", "lmtest", "lubridate", "mapproj", "maps", "MASS", "miniUI", "modelr", "munsell", "openssl", "packrat", "plm", "plogr", "psych", "purrr", "quantreg", "raster", "rasterVis", "Rcpp", "RcppArmadillo", "RcppEigen", "RCurl", "readxl", "reshape2", "rex", "rgbif", "rgdal", "rgeos", "rlang", "rmarkdown", "rstudioapi", "Rttf2pt1", "selectr", "servr", "sf", "shiny", "showtext", "showtextdb", "slam", "sourcetools", "sp", "stringdist", "stringi", "subprocess", "sysfonts", "testthat", "tibble", "tidycensus", "tidyr", "tidyverse", "tigris", "units", "urltools", "viridis", "viridisLite", "wicket", "withr", "xfun", "xml2", "xts", "zoo"))
install.packages("tikz")
install.packages("tikzdevice")
install.packages("tikzDevice")
library(tinytex)
tlmgr_search('/tikz.sty')  # search for framed.sty
tlmgr_install('tikz')
dir.exists("home\\Users\\vince\\AppData\\Roaming\\TinyTeX")
c("meal plan")
substr("meal plan", start = 1)
substr("meal plan", start = 1, stop = 7)
substr("meal plan", start = 1, stop = 4)
twist <- function(x) {
a1 <- substr(x, start = 1, stop = 4)
a2 <- substr(x, start = 6, stop = 8)
a3 <- substr(x, start = 9, stop = 9)
paste0(a1,a2,a3)
}
twist("meal plan")
twist <- function(x) {
a1 <- substr(x, start = 1, stop = 4)
a2 <- substr(x, start = 6, stop = 8)
a3 <- substr(x, start = 9, stop = 9)
paste0(a1,a3, a2)
}
twist("meal plan")
twist <- function(x) {
a1 <- substr(x, start = 1, stop = 4)
a2 <- substr(x, start = 7, stop = 9)
a3 <- substr(x, start = 6, stop = 6)
paste0(a1,a3, a2)
}
twist("meal plan")
twist <- function(x) {
a1 <- substr(x, start = 1, stop = 4)
a2 <- substr(x, start = 7, stop = 9)
a3 <- substr(x, start = 6, stop = 6)
paste0(a1, a2,a3)
}
twist("meal plan")
twist("make love")
twist("move over")
twist("move outs")
twist("mole rats")
twist("meal outs")
twist("male bond")
twist("male band")
twist("mule bear")
twist("mere cats")
twist("meer cats")
twist("more ber")
twist("more beer")
twist("must have")
twist("must sees")
twist("must thaw")
twist("made here")
twist("mine ours")
twist("meal plan")
wibr <- read.csv("wibr.csv")
list.files()
wibr <- read.csv("wibr.csv")
colnames(wibr)
View(wibr)
twist("made over")
twist("mull over")
twist("mole rats")
library(sf)
library(dplyr)
library(ggplot2)
library(gganimate)
sessionInfo()
# install.packages('devtools')
devtools::install_github('thomasp85/gganimate')
install.packages("gifski")
install.packages("cargo")
library(gifski)
library("gifski")
devtools::install_github("r-rust/gifski")
devtools::install_github("r-rust/gifski")
library(gifski)
# install.packages('devtools')
devtools::install_github('thomasp85/gganimate')
remove.packages("gganimate")
# install.packages('devtools')
devtools::install_github('thomasp85/gganimate')
library(gganimate)
library(ggplot2)
remove.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
library(sf)
library(dplyr)
library(ggplot2)
library(gganimate) # needs development version from github
place_geometry <- function(geometry, position, scale = 1) {
(geometry - st_centroid(geometry)) * scale +
st_sfc(st_point(position))
}
# projections
# ESRI:102003
crs_lower48 <- "+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=37.5 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs"
# EPSG:3338
crs_alaska <- "+proj=aea +lat_1=55 +lat_2=65 +lat_0=50 +lon_0=-154 +x_0=0 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs "
# ESRI:
crs_hawaii <- "+proj=aea +lat_1=8 +lat_2=18 +lat_0=13 +lon_0=-157 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs"
getwd()
us_counties_sp <- rgdal::readOGR(dsn = "shp/US_shapes", layer = "shp/cb_2017_us_county_20m")
us_counties_sp <- rgdal::readOGR(dsn = "shp", layer = "cb_2017_us_county_20m")
us_states_sp <- rgeos::gUnaryUnion(us_counties_sp, us_counties_sp$STATEFP)
# collect fips codes; they are the names of the objects after aggregation
us_states_sp$fips_state <- names(us_states_sp)
# convert to sf
us_states <- as(us_states_sp, "sf") %>%
st_transform(crs_lower48) %>%
filter(fips_state != "72") # remove Puerto Rico
# remove Alaska and Hawaii for lower 48
us_lower48 <- filter(us_states, !fips_state %in% c("02", "15"))
bb <- st_bbox(us_lower48)
# scale and move Alaska
us_alaska <- filter(us_states, fips_state == "02")
us_alaska2 <- st_transform(us_alaska, crs_alaska)
st_geometry(us_alaska2) <- place_geometry(
st_geometry(us_alaska2),
c(bb$xmin + 0.08*(bb$xmax - bb$xmin),
bb$ymin + 0.07*(bb$ymax - bb$ymin)),
scale = 0.35
)
st_crs(us_alaska2) <- crs_lower48
# scale and move Hawaii
us_hawaii <- filter(us_states, fips_state == "15")
us_hawaii2 <- st_transform(us_hawaii, crs_hawaii)
st_geometry(us_hawaii2) <- place_geometry(
st_geometry(us_hawaii2),
c(bb$xmin + 0.3*(bb$xmax - bb$xmin),
bb$ymin + 0.*(bb$ymax - bb$ymin))
)
st_crs(us_hawaii2) <- crs_lower48
us_albers <- rbind(us_lower48, us_alaska2, us_hawaii2)
# make animation
x1 <- us_states
x1$type = "a_original"
x2 <- rbind(us_lower48, us_alaska, us_hawaii2)
x2$type = "b_hawaii"
x3 <- us_albers
x3$type = "c_final"
x4 <- x3
x4$type = "d_final"
x <- rbind(x1, x2, x3, x4)
bb1 <- st_bbox(x1)
bb2 <- st_bbox(x3)
ggplot(x, aes(group = fips_state)) +
geom_sf(fill = "#56B4E9", color = "grey30", size = 0.3, alpha = 0.5) +
transition_states(type, 2, 1) +
view_zoom_manual(
2, 1, pause_first = FALSE,
xmin = c(bb1$xmin, bb1$xmin, bb1$xmin, bb2$xmin),
ymin = c(bb1$ymin, bb1$ymin, bb1$ymin, bb2$ymin),
xmax = c(bb1$xmax, bb1$xmax, bb1$xmax, bb2$xmax),
ymax = c(bb1$ymax, bb1$ymax, bb1$ymax, bb2$ymax)
)
# revised animation that keeps Alaska at its size
us_alaska3 <- st_transform(us_alaska, crs_alaska)
st_geometry(us_alaska3) <- place_geometry(
st_geometry(us_alaska3),
c(bb$xmin - 0*(bb$xmax - bb$xmin),
bb$ymin - 0*(bb$ymax - bb$ymin))
)
st_crs(us_alaska3) <- crs_lower48
x1 <- us_states
x1$type = "a_original"
x2 <- rbind(us_lower48, us_alaska, us_hawaii2)
x2$type = "b_hawaii"
x3 <- rbind(us_lower48, us_alaska3, us_hawaii2)
x3$type = "c_final"
x4 <- x3
x4$type = "d_final"
x <- rbind(x1, x2, x3, x4)
bb1 <- st_bbox(x1)
bb2 <- st_bbox(x3)
ggplot(x, aes(group = fips_state)) +
geom_sf(fill = "#56B4E9", color = "grey30", size = 0.3, alpha = 0.5) +
transition_states(type, 2, 1) +
view_zoom_manual(
2, 1, pause_first = FALSE,
xmin = c(bb1$xmin, bb1$xmin, bb1$xmin, bb2$xmin),
ymin = c(bb2$ymin, bb2$ymin, bb2$ymin, bb2$ymin),
xmax = c(bb1$xmax, bb1$xmax, bb1$xmax, bb2$xmax),
ymax = c(bb1$ymax, bb1$ymax, bb1$ymax, bb2$ymax)
)
p <- ggplot(x, aes(group = fips_state)) +
geom_sf(fill = "#56B4E9", color = "grey30", size = 0.3, alpha = 0.5) +
transition_states(type, 2, 1) +
view_zoom_manual(
2, 1, pause_first = FALSE,
xmin = c(bb1$xmin, bb1$xmin, bb1$xmin, bb2$xmin),
ymin = c(bb2$ymin, bb2$ymin, bb2$ymin, bb2$ymin),
xmax = c(bb1$xmax, bb1$xmax, bb1$xmax, bb2$xmax),
ymax = c(bb1$ymax, bb1$ymax, bb1$ymax, bb2$ymax)
)
animate(p)
anim_save(p)
?anim_save
anim_save("alaskaMove.gif", p)
anim_save("alaskaMove.gif", animate(p))
anim_save("alaskaMove.gif", animate(p, length = 3))
anim_save("alaskaMoveFast.gif", animate(p, length = 3))
setwd('/home/michael/Documents/mikeleeco.github.com/')
library(blogdown)
# file.create('.nojekyll')
# blogdown::build_site()
# blogdown::hugo_build()
# serve_site should build the site without errors and display it in the viewer. It's now ready to be pushed to master on github
blogdown::serve_site()
setwd('/home/michael/Documents/mikeleeco.github.com/')
library(blogdown)
# file.create('.nojekyll')
# blogdown::build_site()
# blogdown::hugo_build()
# serve_site should build the site without errors and display it in the viewer. It's now ready to be pushed to master on github
blogdown::serve_site()
setwd('/home/michael/Documents/mikeleeco.github.com/')
library(blogdown)
# file.create('.nojekyll')
# blogdown::build_site()
# blogdown::hugo_build()
# serve_site should build the site without errors and display it in the viewer. It's now ready to be pushed to master on github
blogdown::serve_site()
setwd('/home/michael/Documents/mikeleeco.github.com/')
library(blogdown)
# file.create('.nojekyll')
# blogdown::build_site()
# blogdown::hugo_build()
# serve_site should build the site without errors and display it in the viewer. It's now ready to be pushed to master on github
blogdown::serve_site()
